#!/usr/bin/env python
"""
Comprehensive test runner for OASYS Platform
Runs all tests and generates coverage reports
"""
import os
import sys
import subprocess
import time
from pathlib import Path

def run_command(command, description):
    """Run a command and return success status"""
    print(f"\n{'='*60}")
    print(f"üîÑ {description}")
    print(f"{'='*60}")
    print(f"Running: {command}")
    
    start_time = time.time()
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    end_time = time.time()
    
    print(f"\nOutput:")
    print(result.stdout)
    
    if result.stderr:
        print(f"\nErrors:")
        print(result.stderr)
    
    print(f"\n‚è±Ô∏è  Time taken: {end_time - start_time:.2f} seconds")
    
    if result.returncode == 0:
        print(f"‚úÖ {description} - SUCCESS")
    else:
        print(f"‚ùå {description} - FAILED (Exit code: {result.returncode})")
    
    return result.returncode == 0

def main():
    """Main test runner"""
    print("üöÄ OASYS Platform - Comprehensive Test Suite")
    print("=" * 60)
    
    # Check if we're in the right directory
    if not os.path.exists('manage.py'):
        print("‚ùå Error: manage.py not found. Please run this script from the Django project root.")
        sys.exit(1)
    
    # Test results tracking
    test_results = {}
    
    # 1. Django system check
    success = run_command(
        "python manage.py check --settings=backend.test_settings",
        "Django System Check"
    )
    test_results['system_check'] = success
    
    # 2. Run model tests
    model_tests = [
        ('authentication', 'Authentication Models'),
        ('tenants', 'Tenant Models'),
        ('accounting', 'Accounting Models'),
        ('invoicing', 'Invoicing Models'),
        ('banking', 'Banking Models'),
        ('sales', 'Sales Models'),
        ('purchase', 'Purchase Models'),
        ('ai_processing', 'AI Processing Models'),
        ('web3_integration', 'Web3 Integration Models'),
    ]
    
    for app, description in model_tests:
        success = run_command(
            f"python manage.py test {app}.tests --settings=backend.test_settings --verbosity=2",
            f"{description} Tests"
        )
        test_results[f'{app}_models'] = success
    
    # 3. Run API tests
    api_tests = [
        ('authentication', 'Authentication APIs'),
        ('tenants', 'Tenant APIs'),
        ('accounting', 'Accounting APIs'),
        ('invoicing', 'Invoicing APIs'),
        ('banking', 'Banking APIs'),
        ('sales', 'Sales APIs'),
        ('purchase', 'Purchase APIs'),
        ('ai_processing', 'AI Processing APIs'),
        ('web3_integration', 'Web3 Integration APIs'),
    ]
    
    for app, description in api_tests:
        success = run_command(
            f"python manage.py test {app}.tests --settings=backend.test_settings --verbosity=2",
            f"{description} Tests"
        )
        test_results[f'{app}_apis'] = success
    
    # 4. Run all tests together
    success = run_command(
        "python manage.py test --settings=backend.test_settings --verbosity=2",
        "All Tests Together"
    )
    test_results['all_tests'] = success
    
    # 5. Generate coverage report (if coverage is installed)
    try:
        success = run_command(
            "coverage run --source='.' manage.py test --settings=backend.test_settings",
            "Coverage Analysis"
        )
        test_results['coverage'] = success
        
        if success:
            run_command(
                "coverage report --show-missing",
                "Coverage Report"
            )
            run_command(
                "coverage html",
                "HTML Coverage Report"
            )
    except FileNotFoundError:
        print("\n‚ö†Ô∏è  Coverage not installed. Install with: pip install coverage")
        test_results['coverage'] = False
    
    # 6. Performance tests
    success = run_command(
        "python manage.py test --settings=backend.test_settings --verbosity=1 --parallel",
        "Parallel Performance Tests"
    )
    test_results['performance'] = success
    
    # 7. Security tests
    security_checks = [
        ("python manage.py check --deploy --settings=backend.test_settings", "Security Check"),
        ("python manage.py validate --settings=backend.test_settings", "Model Validation"),
    ]
    
    for command, description in security_checks:
        success = run_command(command, description)
        test_results[f'security_{description.lower().replace(" ", "_")}'] = success
    
    # Print summary
    print(f"\n{'='*60}")
    print("üìä TEST SUMMARY")
    print(f"{'='*60}")
    
    total_tests = len(test_results)
    passed_tests = sum(test_results.values())
    failed_tests = total_tests - passed_tests
    
    print(f"Total Tests: {total_tests}")
    print(f"‚úÖ Passed: {passed_tests}")
    print(f"‚ùå Failed: {failed_tests}")
    print(f"üìà Success Rate: {(passed_tests/total_tests)*100:.1f}%")
    
    print(f"\nDetailed Results:")
    for test_name, result in test_results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {test_name}: {status}")
    
    if failed_tests == 0:
        print(f"\nüéâ ALL TESTS PASSED! The OASYS platform is ready for production!")
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {failed_tests} tests failed. Please review and fix the issues.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
